[build-system]
requires = ["uv_build>=0.9.22,<0.10.0"]
build-backend = "uv_build"

[project]
name = "mlops"
version = "0.0.1"
description = "A short description of the project."
authors = [
  { name = "group120", email = "your@email.com" },
]
keywords = ["machine learning", "MLOps"]
classifiers = [
  "Development Status :: 3 - Alpha",
  "Programming Language :: Python :: 3",
]

readme = "README.md"
requires-python = "~=3.12.0"

#! These are the core dependencies required for the application to run.
dependencies = [
    "fastapi==0.115.6",
    "typer==0.15.1",
    "uvicorn==0.34.0",
    "kaggle>=1.8.3",
    "kagglehub>=0.4.0",
    "pandas>=2.3.3",
    "scikit-learn>=1.8.0",
    "torch==2.3.1",
    "torchvision==0.18.1",

]

# Optional dependency groups. The 'dev' group includes tools for development
# like testing, linting, and documentation, which are not needed in production.
[dependency-groups]
dev = [
    "coverage==7.6.9",
    "invoke==2.2.0",
    "mkdocs-material==9.4.6",
    "mkdocs==1.6.1",
    "pre-commit==4.1.0",
    "pytest==8.3.4",
    "ruff==0.1.3",
    "mkdocstrings-python==1.12.2",
    "mypy==1.19.1",
]

# This section tells 'uv' to use a specific index for certain packages.
# It overrides the default behavior of searching only on PyPI.
[tool.uv.sources]
torch = [
    { index = "pytorch-cuda" },
]
torchvision = [
    { index = "pytorch-cuda" },
]

# This defines a custom package index (an array of tables, hence the double brackets).
# We've named it 'pytorch-cuda' and pointed it to the official PyTorch repository
# for wheels compiled with CUDA 12.1 support.
[[tool.uv.index]]
name = "pytorch-cuda"
url = "https://download.pytorch.org/whl/cu121"
# 'explicit = true' is a performance optimization. It tells uv to only search
# this index for packages that are explicitly mapped to it in [tool.uv.sources].
explicit = true

[tool.ruff]
line-length = 120

[tool.coverage.run]
omit = ["tests/*"]